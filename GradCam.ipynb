{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradCam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaZZjlI01n9TWldRKcog+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b09cf709e97b4c9eb4c44e9ed897f2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1da0206d3e7e45ae9a5a7d46496f39eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f0ce99b89be4fd7a733240769cf618e",
              "IPY_MODEL_1bc193c4514b469d9251b3b313aca08e"
            ]
          }
        },
        "1da0206d3e7e45ae9a5a7d46496f39eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f0ce99b89be4fd7a733240769cf618e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dcba1fdb2a2d4d61b374d8f946b0287b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27e3d6417fbf476eb27f48968d38be69"
          }
        },
        "1bc193c4514b469d9251b3b313aca08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b5b3a8010b64e2b84e87c2f0e6012e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 33456293.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_525a127977b648c08be614204135fa00"
          }
        },
        "dcba1fdb2a2d4d61b374d8f946b0287b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27e3d6417fbf476eb27f48968d38be69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b5b3a8010b64e2b84e87c2f0e6012e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "525a127977b648c08be614204135fa00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c59abc5245445229f3900df42d4eda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9e7a49e488e4a9d95ef962956d8c2a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c986be2e36a45bdbf2085efe3cd9a35",
              "IPY_MODEL_7dc166ace3af401991df06b2d750e312"
            ]
          }
        },
        "c9e7a49e488e4a9d95ef962956d8c2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c986be2e36a45bdbf2085efe3cd9a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c0abb9bc5654e7baa0427c40838dbcd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5207b7278a14f7b89e56acc5fc65b55"
          }
        },
        "7dc166ace3af401991df06b2d750e312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_542ff144b4dd40aca5046905fcfc2054",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:02&lt;00:00, 44.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4066526c82f84135b425905bd3a5ed1a"
          }
        },
        "6c0abb9bc5654e7baa0427c40838dbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5207b7278a14f7b89e56acc5fc65b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "542ff144b4dd40aca5046905fcfc2054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4066526c82f84135b425905bd3a5ed1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TakafumiMatsuda/Python-Training/blob/update1/GradCam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-O_Xayn6o6V",
        "colab_type": "code",
        "outputId": "c8306b6d-29c0-4856-a07b-15870ec1a914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #GPU使えるかどうか調べる\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBk18G5kz2oR",
        "colab_type": "code",
        "outputId": "b8f80ce9-1ab0-4661-a7f5-74a132796ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "b09cf709e97b4c9eb4c44e9ed897f2b5",
            "1da0206d3e7e45ae9a5a7d46496f39eb",
            "2f0ce99b89be4fd7a733240769cf618e",
            "1bc193c4514b469d9251b3b313aca08e",
            "dcba1fdb2a2d4d61b374d8f946b0287b",
            "27e3d6417fbf476eb27f48968d38be69",
            "0b5b3a8010b64e2b84e87c2f0e6012e4",
            "525a127977b648c08be614204135fa00"
          ]
        }
      },
      "source": [
        "#####Loading and normalizing CIFAR10 2#####\n",
        "trabsize=400\n",
        "#trabsize=4\n",
        "valbsize=100\n",
        "tesbsize=4\n",
        "# 画像の変換処理を定義する（画像をtorch.Tensorに変換し、3つあるチャネル毎に標準化（平均0.5、標準偏差0.5）する）\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10のトレーニングデータをダウンロードしtransformで変換\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) #download=True：rootの位置にデータを保存\n",
        "#print(trainset.__getitem__(0)[0].shape)\n",
        "\n",
        "n_samples = len(trainset) # n_samples is 60000\n",
        "print('CIFAR10のtraindataset数: ', len(trainset)) # 50000\n",
        "train_size = int(len(trainset) * 0.8) # train_size is 40000\n",
        "val_size = n_samples - train_size # val_size is 10000\n",
        "# shuffleしてtrainsetとvalidationsetに分割\n",
        "train_splitset, valid_splitset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
        "print('分割後トレーニングデータ数: ',len(train_splitset)) # 40000\n",
        "print('分割後検証データ数: ',len(valid_splitset)) # 10000\n",
        "\n",
        "# トレーニングデータの読み込み方を定義（ミニバッチに分け、エポック毎にシャッフルして再度ミニバッチを作る）（2つのサブプロセスに分けて並列処理）\n",
        "trainloader = torch.utils.data.DataLoader(train_splitset, batch_size=trabsize, shuffle=False, num_workers=2) #シャッフルなしにしてる\n",
        "validloader = torch.utils.data.DataLoader(valid_splitset, batch_size=valbsize, shuffle=False, num_workers=2)\n",
        "# CIFAR10のテストデータをダウンロードし、transformで変換する\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# テストデータの読み込み方を定義（テストデータはシャッフルする必要なし）\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=tesbsize, shuffle=False, num_workers=2)\n",
        "print('テストデータ数: ',len(testset)) # 10000\n",
        "\n",
        "# CIFAR10のクラスラベル\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b09cf709e97b4c9eb4c44e9ed897f2b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "CIFAR10のtraindataset数:  50000\n",
            "分割後トレーニングデータ数:  40000\n",
            "分割後検証データ数:  10000\n",
            "Files already downloaded and verified\n",
            "テストデータ数:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5mpjcb_OhAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###★★事前学習済Net★★###\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    resnet = models.resnet50(pretrained=True)\n",
        "    self.resnet = nn.Sequential(*list(resnet.children())[:-2]) #Global Average Poolingを削除してresnet\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=1) #Max Pooling層追加\n",
        "    self.fc = nn.Linear(2048, 10) #出力を10次元に\n",
        "\n",
        "  def forward(self,x):\n",
        "    #print(x.shape) #[400, 3, 32, 32]\n",
        "    x = self.resnet(x)\n",
        "    #print(x.shape) #[400, 2048, 1, 1]\n",
        "    x = self.maxpool(x)\n",
        "    #print(x.shape) #[400, 2048, 1, 1]\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #print(x.shape) #[400, 2048]\n",
        "    x = self.fc(x)\n",
        "    #print(x.shape) #[400, 10]\n",
        "    return x\n",
        "\n",
        "# resnet = nn.Sequential(*list(resnet.children())[:-3]) # 一部の層のみを使いたい場合\n",
        "\n",
        "#net = Net() #インスタンス化している！net.forward(x)として使えるようになる\n",
        "#net.to(device) #GPUに渡す"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7oJu99HQPIQ",
        "colab_type": "code",
        "outputId": "23809d9e-5cb3-4fc7-bd7a-d067bfe3190c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "7c59abc5245445229f3900df42d4eda0",
            "c9e7a49e488e4a9d95ef962956d8c2a1",
            "0c986be2e36a45bdbf2085efe3cd9a35",
            "7dc166ace3af401991df06b2d750e312",
            "6c0abb9bc5654e7baa0427c40838dbcd",
            "b5207b7278a14f7b89e56acc5fc65b55",
            "542ff144b4dd40aca5046905fcfc2054",
            "4066526c82f84135b425905bd3a5ed1a"
          ]
        }
      },
      "source": [
        "#####Define a Loss function and optimizer#####\n",
        "import torch.optim as optim\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss() # 損失関数: クロスエントロピー（確率的勾配降下法との相性が良いため2乗和誤差よりもよく使われる）\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #最適化アルゴリズム: SGD　#学習率: 0.001、モメンタムのパラメータ: 0.9に設定\n",
        "\n",
        "\n",
        "#schedular = ExponentialLR(optimizer, gamma=0.95)\n",
        "#net.parameters()がCNNの全パラメータを保持"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c59abc5245445229f3900df42d4eda0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=102502400), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wBup3g_Onva",
        "colab_type": "code",
        "outputId": "f118673c-7e3a-477b-cad1-ddcf11195fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "###★★Train★★###\n",
        "#net.train() #学習モードにする\n",
        "\n",
        "print('トレーニングデータ数: ', len(train_splitset))\n",
        "print('検証データ数: ', len(valid_splitset))\n",
        "print('トレーニングデータバッチあたり数: ', len(train_splitset)/len(trainloader)) #=trabsizeになるはず\n",
        "print('トレーニングデータバッチ数: ', len(trainloader)) \n",
        "running_trainloss_list=[]\n",
        "running_validloss_list=[]\n",
        "tacu_list=[]\n",
        "vacu_list=[]\n",
        "for epoch in range(1): #epochループ epoch=5なので同じデータを5回学習させることになる\n",
        "    running_trainloss = 0.0 #損失関数の累積値（初期値0）\n",
        "    running_validloss = 0.0 #損失関数の累積値（初期値0）\n",
        "    ### ミニバッチ毎に学習をループ（インデックスは0スタート）\n",
        "    for i, tdata in enumerate(trainloader, 0): #enumerate: リストの要素とインデックスを取得\n",
        "        #print('ミニバッチ番号', i) #\n",
        "        # ミニバッチのデータとラベルを取得\n",
        "        traininputs, trainlabels = tdata[0].to(device), tdata[1].to(device) #GPUに送る\n",
        "\n",
        "        optimizer.zero_grad() #grad(勾配)を0に初期化 #backwardメソッドでは勾配が累積されるため、バッチループ毎に勾配を初期化する\n",
        "        #trainoutputs = net(traininputs) # 順伝播\n",
        "        trainoutputs = model(traininputs) # 順伝播\n",
        "        trainloss = criterion(trainoutputs, trainlabels) # 損失関数計算\n",
        "\n",
        "        # 損失関数の累積値を計算\n",
        "        running_trainloss += trainloss.item() # （.item()はゼロ次元テンソルから値を取り出す（loss.data[0]と書く必要がない））\n",
        "        running_trainloss_list.append(running_trainloss) # 損失関数累積値のミニバッチ毎のリスト作成 # append(): リスト末尾に要素を追加\n",
        "\n",
        "        # 10バッチ毎に損失関数の平均値を表示\n",
        "        if i % 10 == 9:    # %=余り\n",
        "            print('epoch: %d, batch: %5d, train_loss: %.3f' % (epoch + 1, i + 1, running_trainloss / 10)) # エポック、バッチ、損失関数のバッチ平均値の順に表示\n",
        "            running_trainloss = 0.0 # 損失関数の累積値を0で初期化\n",
        "\n",
        "        #####validデータのlossを計算する\n",
        "        # ミニバッチ毎にloss計算をループ（インデックスは0スタート）\n",
        "\n",
        "        vdata = next(iter(validloader)) # いけたあああああああああああああ\n",
        "        validinputs, validlabels = vdata[0].to(device), vdata[1].to(device) # GPUに送る\n",
        "        #validoutputs = net(validinputs) # 順伝播\n",
        "        validoutputs = model(validinputs) # 順伝播\n",
        "        validloss = criterion(validoutputs, validlabels) # 損失関数計算\n",
        "        running_validloss += validloss.item() # 損失関数の累積値を計算\n",
        "        running_validloss_list.append(running_validloss) # 損失関数累積値のミニバッチ毎のリスト\n",
        "\n",
        "        # 10バッチ毎に損失関数の平均値を表示\n",
        "        if i % 10 == 9:\n",
        "            #print('epoch: %d, batch: %5d, valid_loss: %.3f' %(epoch + 1, i + 1, running_validloss / 10)) # エポック、バッチ、損失関数のバッチ平均値の順に表示\n",
        "            running_validloss = 0.0 # 損失関数の累積値を0で初期化\n",
        "        #################################\n",
        "        \n",
        "        # ニューラルネットを更新\n",
        "        trainloss.backward() # 逆伝播\n",
        "        optimizer.step() # ★★★損失関数からCNNのパラメータ（重みとバイアス）を計算して更新\n",
        "        #print(net.parameters()) #パラメータ見てみる→<generator object Module.parameters at 0x7f970b7c0db0>\n",
        "\n",
        "        #####accuracyを見る\n",
        "        ttotal = 0\n",
        "        tcorrect = 0\n",
        "        vtotal = 0\n",
        "        vcorrect = 0\n",
        "\n",
        "        # トレーニングデータ予測\n",
        "        _, tpredicted = torch.max(trainoutputs.data, 1) # trainデータセットをミニバッチ毎に予測\n",
        "        ttotal += trainlabels.size(0) # 予測したデータ数を加算\n",
        "        tcorrect += (tpredicted == trainlabels).sum().item() # 正解したデータ数を加算\n",
        "        tacu = 100 * tcorrect / ttotal # 正解率\n",
        "        tacu_list.append(tacu)\n",
        "\n",
        "        # 検証データ予測\n",
        "        _, vpredicted = torch.max(validoutputs.data, 1)\n",
        "        vtotal += validlabels.size(0)\n",
        "        vcorrect += (vpredicted == validlabels).sum().item()\n",
        "        vacu = 100 * vcorrect / vtotal\n",
        "        vacu_list.append(vacu)\n",
        "        \n",
        "        # 全体の正解率を表示\n",
        "        #if i % 10 == 9:\n",
        "          #print('Accuracy of the network on the 400 train images: %d %%' % (100 * tcorrect / ttotal))\n",
        "          #print('Accuracy of the network on the 100 valid images: %d %%' % (100 * vcorrect / vtotal))\n",
        "        #########################\n",
        "\n",
        "# 学習終了のメッセージ\n",
        "print('Finished Training')\n",
        "\n",
        "#1.重みとバイアスを初期化する。\n",
        "#2.以下を学習回数ぶん繰り返す。\n",
        "#  2-1.以下を入力のぶん繰り返す。\n",
        "#      2-1-1.現在の重みとバイアスを使い、入力データから各層の値を計算する (順伝播)。\n",
        "#      2-1-2.損失関数を計算する。偏微分の計算に直接必要ではないが、学習の経過を確認できる。\n",
        "#      2-1-3.損失関数に対する各層の重みとバイアスの偏微分を計算する。\n",
        "#  2-2入力ごとの損失関数に対する偏微分 (∂L/∂w∂L/∂w) から、全体損失関数に対する偏微分 (∂L(all)/∂w∂L(all)/∂w) を計算する。\n",
        "#  2-3.最急降下法を使い、重みとバイアスを修正する。"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "トレーニングデータ数:  40000\n",
            "検証データ数:  10000\n",
            "トレーニングデータバッチあたり数:  400.0\n",
            "トレーニングデータバッチ数:  100\n",
            "epoch: 1, batch:    10, train_loss: 2.330\n",
            "epoch: 1, batch:    20, train_loss: 2.204\n",
            "epoch: 1, batch:    30, train_loss: 2.041\n",
            "epoch: 1, batch:    40, train_loss: 1.915\n",
            "epoch: 1, batch:    50, train_loss: 1.761\n",
            "epoch: 1, batch:    60, train_loss: 1.635\n",
            "epoch: 1, batch:    70, train_loss: 1.478\n",
            "epoch: 1, batch:    80, train_loss: 1.367\n",
            "epoch: 1, batch:    90, train_loss: 1.288\n",
            "epoch: 1, batch:   100, train_loss: 1.205\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24xnukDmX77L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####quickly save our trained model#####\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(model.state_dict(), PATH) #torch.save(model名.state_dict(), PATH)でモデルを保存"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCMIs1W8Xw_E",
        "colab_type": "code",
        "outputId": "2f01e787-feb1-4d82-fb97-879adf32df89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "###Grad-CAMによる可視化\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "#Flattenの実装(PyTorchには，多次元配列を1次元の配列に変換する．Flattenがないので実装)\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "#特徴設計部の最終出力 & 識別部の出力を取得\n",
        "feature_fn = torch.nn.Sequential(*list(model.children())[:-1]).to(device) #Sequentialにリストを渡してやる\n",
        "#print(list(model.children())[:-2]) #[:-2]: リストの最後の2つのを除いた要素（MaxPoolまで）\n",
        "print(feature_fn) \n",
        "\n",
        "#classfier_fn = torch.nn.Sequential(*( list( model.children())[-2:-1] + [Flatten()] + list(model.children())[-1:]) ).to(device)\n",
        "classfier_fn = torch.nn.Sequential(*( [Flatten()] + list(model.children())[-1:]) ).to(device)\n",
        "print(classfier_fn) \n",
        "\n",
        "\n",
        "\n",
        "###勾配とか取り出してみる###\n",
        "#i = 0\n",
        "#for param in feature_fn.parameters():\n",
        "#    i = i + 1\n",
        "#    if i > 157:\n",
        "#       print(i)\n",
        "#       print(param)\n",
        "\n",
        "#i = 0\n",
        "#for param in classfier_fn.parameters():\n",
        "#    i = i + 1\n",
        "#    if i > 0:\n",
        "#       print(i)\n",
        "#       print(param)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (1): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Flatten()\n",
            "  (1): Linear(in_features=2048, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbcOXBmOb2R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GradCAM定義\n",
        "def GradCam(img, c, feature_fn, classifier_fn): #(input, class label, 特徴量層, 全結合層)\n",
        "    #print('img = ',img.shape) #torch.Size([1, 3, 32, 32])\n",
        "    feature_fn.eval()\n",
        "    classifier_fn.eval()\n",
        "    feats = feature_fn(img.to(device)) #img\n",
        "    _, N, H, W = feats.size()\n",
        "\n",
        "    #print(feats.size()) #torch.Size([1, 2048, 1, 1]) = print(feats.shape)\n",
        "    #print(feats.size(0)) #1\n",
        "    #print(feats.view(-1,2).size()) #2列にする ([1024,2])\n",
        "    #print(feats.view(-1,1).size()) #1列にする ([2048,1])\n",
        "    #print(feats.view(-1,1,1,1).size())  #([2048,1,1,1])\n",
        "    #print(feats.view(1,-1,1,1).size()) #([1,2048,1,1])\n",
        "    #print(feats.view(feats.size(0),-1).size()) #([1,2048])\n",
        "    #view: 4次元(1, 直前のoutputチャネル数, kernel, kernel)のデータを2次元(batch, output*out*ker*ker)に [1, 2048*1*1]=[1, 2048]\n",
        "    out = classifier_fn(feats.view(feats.size(0), -1))\n",
        "    c_score = out[0, c]\n",
        "    print('c_socore=',c_score)\n",
        "    grads = torch.autograd.grad(c_score, feats) #(input, output): inputに対するoutputの勾配の合計\n",
        "    print('grad=',grads)\n",
        "    w = grads[0][0].mean(-1).mean(-1) #全ピクセルについて平均\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = F.relu(sal) #Reluを行う\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0)\n",
        "    return sal, out, c_score, feats, grads, w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY6J22JjYGkN",
        "colab_type": "code",
        "outputId": "c5ead377-6e43-4abb-fb67-c62396f8ca9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "###GradCAMの実行\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "#対象画像の取得\n",
        "#i=0\n",
        "#for data in testloader:\n",
        "#    i=i+1\n",
        "#    print('batch数='i)\n",
        "\n",
        "#for nd in 11:\n",
        "#    data = next(iter(testloader))\n",
        "#    print(len(data)) #3\n",
        "\n",
        "input_index = 0 #0~9999を指定できる（全てのテストデータ）\n",
        "input_data = testloader.dataset[input_index][0]\n",
        "print(len(input_data)) #3\n",
        "input_data = input_data.view(1, input_data.shape[0], input_data.shape[1], input_data.shape[2]).to(device)\n",
        "#print(input_data.shape[0]) #1\n",
        "#print(input_data.shape[1]) #3\n",
        "#print(input_data.shape[2]) #32\n",
        "#print(input_data.__getitem__(0)[0].shape) #[32, 32]\n",
        "#print(len(input_data)) #1\n",
        "\n",
        "model.eval()\n",
        "#上位10クラスの識別部の出力 & クラスラベルを取得\n",
        "pp, cc = torch.topk(nn.Softmax(dim=1)(model(input_data)), 10) \n",
        "#topk()は，上位kクラスのデータとクラスラベルを取得する関数\n",
        "#pp → CNNモデルの出力層の出力\n",
        "#cc → それに対応するクラスラベル\n",
        "\n",
        "#print('pp=',pp) #[0.9843, 0.0116]\n",
        "#print('cc=',cc) #[8,0]\n",
        "#print(cc[0])\n",
        "#print(cc[0][0]) #8\n",
        "\n",
        "#saliency mapの取得\n",
        "sal, out, c_score, feats, grads, w = GradCam(input_data, cc[0][0], feature_fn, classfier_fn)\n",
        "print('class_label=',cc[0][0])\n",
        "print('class_label=',cc[0][1])\n",
        "print('class_label=',cc[0][2])\n",
        "print('class_label=',cc[0][9])\n",
        "#sal → cc[0][0]で指定したクラスラベルにおける勾配のSaliency Map\n",
        "#cc[0][0]\n",
        "\n",
        "#取得したSaliency Mapを画像化\n",
        "img = input_data.permute(0, 2, 3, 1).view(input_data.shape[2], input_data.shape[3], input_data.shape[1]).cpu().numpy()\n",
        "img_sal = Image.fromarray(sal).resize(img.shape[0:2], resample=Image.LINEAR)\n",
        "\n",
        "#表示\n",
        "plt.imshow(img)\n",
        "plt.imshow(np.array(img_sal), alpha=0.5, cmap=\"jet\")\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "c_socore= tensor(2.0610, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "grad= (tensor([[[[ 0.0087]],\n",
            "\n",
            "         [[-0.0029]],\n",
            "\n",
            "         [[-0.0072]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0148]],\n",
            "\n",
            "         [[-0.0038]],\n",
            "\n",
            "         [[ 0.0143]]]], device='cuda:0'),)\n",
            "class_label= tensor(3, device='cuda:0')\n",
            "class_label= tensor(1, device='cuda:0')\n",
            "class_label= tensor(5, device='cuda:0')\n",
            "class_label= tensor(4, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f69dbcec6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAD6CAYAAAAvFLvvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nayt3Khb0UqcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIjgidXOYIgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9L-bajkPfrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}